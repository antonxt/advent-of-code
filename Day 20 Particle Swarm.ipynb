{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "## Part 1 - Closest to (0,0,0) in the long run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T23:52:05.752253Z",
     "start_time": "2017-12-30T23:52:05.687513Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load(file_name):\n",
    "    file = open(file_name, 'r')\n",
    "    poss = []\n",
    "    vels = []\n",
    "    accs = []\n",
    "    for s in file:\n",
    "        poss.append(tuple(int(n) for n in s[s.find('p=<')+3:s.find('>, v=<')].split(',')))\n",
    "        vels.append(tuple(int(n) for n in s[s.find('v=<')+3:s.find('>, a=<')].split(',')))\n",
    "        accs.append(tuple(int(n) for n in s[s.find('a=<')+3:s.rfind('>')].split(',')))\n",
    "    return np.array(poss), np.array(vels), np.array(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T23:52:05.767450Z",
     "start_time": "2017-12-30T23:52:05.754028Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to part 1 - particle whose acceleration is the lowest = [150]\n"
     ]
    }
   ],
   "source": [
    "poss, vels, accs = load('in/day20.txt')\n",
    "acc_mds = np.abs(accs).sum(axis=-1)  # Absolute values of accelerations of each particle\n",
    "min_abs_acc = np.where(acc_mds == acc_mds.min())[0]  # Array of indexes with absolute acceleration = min\n",
    "# If there were more than 1 such particles - initial velocity should have been considered.\n",
    "print('Answer to part 1 - particle whose acceleration is the lowest = {}'.format(min_abs_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "## Part 2 - How many particles collided?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T23:52:05.959335Z",
     "start_time": "2017-12-30T23:52:05.769638Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation with 1000 particles\n",
      "t=09, after collisions remain 979 979 979 particles\n",
      "t=10, after collisions remain 972 972 972 particles\n",
      "t=11, after collisions remain 956 956 956 particles\n",
      "t=12, after collisions remain 948 948 948 particles\n",
      "t=13, after collisions remain 933 933 933 particles\n",
      "t=15, after collisions remain 921 921 921 particles\n",
      "t=16, after collisions remain 896 896 896 particles\n",
      "t=17, after collisions remain 881 881 881 particles\n",
      "t=19, after collisions remain 864 864 864 particles\n",
      "t=20, after collisions remain 840 840 840 particles\n",
      "t=22, after collisions remain 831 831 831 particles\n",
      "\n",
      "True [[  0 -16 -12]]\n",
      "\n",
      "t=23, count=831 831 831, collisions:1\n",
      "[[    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [    0   -16   -12]\n",
      " [ 2358 -1602   -12]]\n",
      "\n",
      "[[  0 -16 -12]]\n",
      "\n",
      "[10  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "t=23, after collisions remain 820 820 820 particles\n",
      "t=24, after collisions remain 797 797 797 particles\n",
      "t=25, after collisions remain 780 780 780 particles\n",
      "t=26, after collisions remain 767 767 767 particles\n",
      "t=27, after collisions remain 754 754 754 particles\n",
      "t=28, after collisions remain 745 745 745 particles\n",
      "t=29, after collisions remain 733 733 733 particles\n",
      "t=30, after collisions remain 728 728 728 particles\n",
      "t=32, after collisions remain 716 716 716 particles\n",
      "t=33, after collisions remain 707 707 707 particles\n",
      "t=35, after collisions remain 691 691 691 particles\n",
      "t=36, after collisions remain 676 676 676 particles\n",
      "t=37, after collisions remain 673 673 673 particles\n",
      "t=38, after collisions remain 644 644 644 particles\n",
      "\n",
      "Part 2 answer: 644\n"
     ]
    }
   ],
   "source": [
    "p, v, a = np.array(poss), np.array(vels), np.array(accs)\n",
    "print(f'Starting simulation with {len(p)} particles')\n",
    "for t in range(100):\n",
    "    v += a\n",
    "    p += v\n",
    "    unique, idx, inverse_idx, counts = np.unique(p, axis=0, return_index=True, return_inverse=True, return_counts=True)\n",
    "    collision_mask = counts > 1\n",
    "    if True in collision_mask:  # Collisions (non-unique positions) found\n",
    "        collision_idx = idx[collision_mask]\n",
    "        collision_poss = unique[collision_mask]  # Duplicated positions (collisions) to be removed\n",
    "        collision_idx = [i for i in range(p.shape[0]) if p[i] in collision_poss]\n",
    "        if t == 23:\n",
    "            print(f'\\n{[2358,-1602,-12] in collision_poss} {collision_poss}')\n",
    "            print(f'\\nt={t:02}, count={len(p)} {len(v)} {len(a)}, \\\n",
    "collisions:{collision_mask.sum()}\\n{p[collision_idx]}\\n\\n{unique[collision_mask]}\\n\\n{counts}')\n",
    "        p = np.delete(p, collision_idx, axis=0)\n",
    "        v = np.delete(v, collision_idx, axis=0)\n",
    "        a = np.delete(a, collision_idx, axis=0)\n",
    "        print(f't={t:02}, after collisions remain {len(p)} {len(v)} {len(a)} particles')\n",
    "\n",
    "print(f'\\nPart 2 answer: {len(p)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T23:52:05.968714Z",
     "start_time": "2017-12-30T23:52:05.961288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2, 3, 4, 5, 6]), array([0, 1, 2, 3, 4, 5, 5, 4, 3, 2, 3, 2]), array([1, 1, 3, 3, 2, 2]))\n",
      "[0 1 5]\n"
     ]
    }
   ],
   "source": [
    "ar = np.array([1,2,3,4,5,6,6,5,4,3,4,3])\n",
    "print(np.unique(ar, return_counts=True, return_inverse=True))\n",
    "print(np.searchsorted(ar, [1,2,6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "### Part 2 answers\n",
    "Too high: `772`.\n",
    "\n",
    "Incorrect: `644`, `663`.\n",
    "\n",
    "Correct: `657`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "# Someone elses' solution\n",
    "[Here](https://gist.github.com/GlenboLake/91fa9b990e46b6b624704e9a1c7495c8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-30T23:52:13.547794Z",
     "start_time": "2017-12-30T23:52:05.970713Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: 150\n",
      "Part 2: 657\n",
      "Took 7.107012748718262s\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from cmath import sqrt\n",
    "from collections import defaultdict, namedtuple\n",
    "from functools import reduce\n",
    "from itertools import combinations\n",
    "from time import time\n",
    "\n",
    "Particle = namedtuple('Particle', ['pos', 'vel', 'acc'])\n",
    "\n",
    "def parse_particle(line):\n",
    "    pos_match = re.search('p=<(-?\\d+),(-?\\d+),(-?\\d+)>', line)\n",
    "    position = (int(pos_match.group(1)), int(pos_match.group(2)), int(pos_match.group(3)))\n",
    "    vel_match = re.search('v=<(-?\\d+),(-?\\d+),(-?\\d+)>', line)\n",
    "    velocity = (int(vel_match.group(1)), int(vel_match.group(2)), int(vel_match.group(3)))\n",
    "    acc_match = re.search('a=<(-?\\d+),(-?\\d+),(-?\\d+)>', line)\n",
    "    acceleration = (int(acc_match.group(1)), int(acc_match.group(2)), int(acc_match.group(3)))\n",
    "    return Particle(position, velocity, acceleration)\n",
    "\n",
    "def particle_at(particle, t):\n",
    "    x = particle.pos[0] + particle.vel[0] * t + particle.acc[0] * t * (t + 1) // 2\n",
    "    y = particle.pos[1] + particle.vel[1] * t + particle.acc[1] * t * (t + 1) // 2\n",
    "    z = particle.pos[2] + particle.vel[2] * t + particle.acc[2] * t * (t + 1) // 2\n",
    "    return x, y, z\n",
    "\n",
    "def manhattan(point):\n",
    "    return sum(map(abs, point))\n",
    "\n",
    "def part1(particles):\n",
    "    max_accel = max(sum(map(abs, p.acc)) for p in particles)\n",
    "    return particles.index(min(particles, key=lambda p: manhattan(particle_at(p, 100 * max_accel))))\n",
    "\n",
    "def will_collide(p1, p2):\n",
    "    def is_int(c):\n",
    "        return c.imag == 0 and (isinstance(c.real, int) or c.real.is_integer())\n",
    "\n",
    "    def solve_quadratic(a, b, c):\n",
    "        solutions = None\n",
    "        if a:\n",
    "            solutions = {(-b - sqrt(b ** 2 - 4 * a * c)) / (2 * a), (-b + sqrt(b ** 2 - 4 * a * c)) / (2 * a)}\n",
    "        elif b:\n",
    "            solutions = {-c / b}\n",
    "        elif c:\n",
    "            solutions = {c}\n",
    "        if solutions is not None:\n",
    "            solutions = set(map(lambda x: int(x.real), filter(is_int, solutions)))\n",
    "        return solutions\n",
    "\n",
    "    diff = Particle(tuple(a - b for a, b in zip(p1.pos, p2.pos)),\n",
    "                    tuple(a - b for a, b in zip(p1.vel, p2.vel)),\n",
    "                    tuple(a - b for a, b in zip(p1.acc, p2.acc)))\n",
    "    tuples = [\n",
    "        (diff.acc[0], diff.vel[0], diff.pos[0]),\n",
    "        (diff.acc[1], diff.vel[1], diff.pos[1]),\n",
    "        (diff.acc[2], diff.vel[2], diff.pos[2]),\n",
    "    ]\n",
    "    solutions = reduce(lambda a, b: a & b,\n",
    "                       filter(lambda s: s is not None,\n",
    "                              [solve_quadratic(a / 2, v + a / 2, p) for a, v, p in tuples]))\n",
    "\n",
    "    if solutions:\n",
    "        return min(s for s in solutions if s > 0)\n",
    "    return None\n",
    "\n",
    "def pairs_to_sets(data):\n",
    "    items = {a for a, b in data} | {b for a, b in data}\n",
    "    sets = []\n",
    "    seen = set()\n",
    "    for item in items:\n",
    "        if item in seen:\n",
    "            continue\n",
    "        new_set = set()\n",
    "        seen.add(item)\n",
    "        for pair in data:\n",
    "            if item in pair:\n",
    "                seen.update(set(pair))\n",
    "                new_set.update(set(pair))\n",
    "        sets.append(new_set)\n",
    "    return sets\n",
    "\n",
    "def part2(particles):\n",
    "    collisions = defaultdict(list)\n",
    "    for a, b in combinations(particles, 2):\n",
    "        t = will_collide(a, b)\n",
    "        if t is not None:\n",
    "            collisions[t].append({a, b})\n",
    "    collisions = {k: pairs_to_sets(v) for k, v in collisions.items()}\n",
    "    remaining = set(particles)\n",
    "    for t, splosions in sorted(collisions.items()):\n",
    "        for s in splosions:\n",
    "            if len(remaining & s) > 1:\n",
    "                remaining -= s\n",
    "    return len(remaining)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    particles = [parse_particle(line) for line in open('in/day20.txt')]\n",
    "\n",
    "    start = time()\n",
    "    print('Part 1:', part1(particles))\n",
    "    print('Part 2:', part2(particles))\n",
    "    print(f'Took {time()-start}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "none",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
